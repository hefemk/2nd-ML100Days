{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day_077_HW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wbG0IiA2boj",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
        "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VUai17Y2bop",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e762e65-8fa4-4156-ab1f-f3962ad84632"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_rQGAj92bo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9b0936a6-b5ce-4c78-8a46-b13e3c0f6038"
      },
      "source": [
        "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZY4WBZx2bo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將 X 與 Y 獨立放進變數\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "# 資料前處理 - 標準化\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "x_test = x_test.reshape((len(x_test), -1))\n",
        "\n",
        "# 將目標轉為 one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqd1BvmE2bpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "40a324da-c4e7-4895-ad90-9886e172cbb8"
      },
      "source": [
        "def build_mlp():\n",
        "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
        "    x = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
        "    x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(units=128, activation=\"relu\")(x)\n",
        "    out = keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "\n",
        "    return model\n",
        "model = build_mlp()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0805 12:57:59.381998 140377877895040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0805 12:57:59.425502 140377877895040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0805 12:57:59.433524 140377877895040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aU_kaIZ3KLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "1faf3dfe-b2d5-4ebf-954c-a290c3d30bd2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy-IC1AT2bpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "22daf17d-abce-48e7-e670-5336b9daf9de"
      },
      "source": [
        "optimizer = keras.optimizers.SGD(lr=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 12:59:46.137555 140377877895040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0805 12:59:46.153336 140377877895040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sEuIbLzZ2bpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21454c53-3aa9-4c3e-d3d9-4a76884c972c"
      },
      "source": [
        "\"\"\"\n",
        "設定要訓練的 Epoch 數\n",
        "\"\"\"\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=500, \n",
        "          batch_size=256, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0805 13:00:03.922575 140377877895040 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0805 13:00:03.986100 140377877895040 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 2.2736 - acc: 0.1610 - val_loss: 2.2201 - val_acc: 0.2020\n",
            "Epoch 2/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 2.1834 - acc: 0.2264 - val_loss: 2.1546 - val_acc: 0.2528\n",
            "Epoch 3/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 2.1246 - acc: 0.2617 - val_loss: 2.1020 - val_acc: 0.2764\n",
            "Epoch 4/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 2.0776 - acc: 0.2836 - val_loss: 2.0595 - val_acc: 0.2925\n",
            "Epoch 5/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 2.0388 - acc: 0.2982 - val_loss: 2.0249 - val_acc: 0.3021\n",
            "Epoch 6/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 2.0074 - acc: 0.3080 - val_loss: 1.9958 - val_acc: 0.3156\n",
            "Epoch 7/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.9811 - acc: 0.3162 - val_loss: 1.9721 - val_acc: 0.3224\n",
            "Epoch 8/500\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.9591 - acc: 0.3215 - val_loss: 1.9529 - val_acc: 0.3238\n",
            "Epoch 9/500\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.9404 - acc: 0.3267 - val_loss: 1.9343 - val_acc: 0.3311\n",
            "Epoch 10/500\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.9242 - acc: 0.3320 - val_loss: 1.9196 - val_acc: 0.3333\n",
            "Epoch 11/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.9099 - acc: 0.3352 - val_loss: 1.9070 - val_acc: 0.3365\n",
            "Epoch 12/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.8973 - acc: 0.3377 - val_loss: 1.8938 - val_acc: 0.3385\n",
            "Epoch 13/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.8862 - acc: 0.3412 - val_loss: 1.8830 - val_acc: 0.3435\n",
            "Epoch 14/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.8763 - acc: 0.3437 - val_loss: 1.8745 - val_acc: 0.3448\n",
            "Epoch 15/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.8672 - acc: 0.3472 - val_loss: 1.8650 - val_acc: 0.3459\n",
            "Epoch 16/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.8589 - acc: 0.3489 - val_loss: 1.8578 - val_acc: 0.3465\n",
            "Epoch 17/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.8508 - acc: 0.3508 - val_loss: 1.8496 - val_acc: 0.3570\n",
            "Epoch 18/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.8432 - acc: 0.3544 - val_loss: 1.8429 - val_acc: 0.3542\n",
            "Epoch 19/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.8362 - acc: 0.3577 - val_loss: 1.8355 - val_acc: 0.3538\n",
            "Epoch 20/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.8296 - acc: 0.3591 - val_loss: 1.8286 - val_acc: 0.3559\n",
            "Epoch 21/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.8228 - acc: 0.3613 - val_loss: 1.8232 - val_acc: 0.3579\n",
            "Epoch 22/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.8168 - acc: 0.3646 - val_loss: 1.8170 - val_acc: 0.3638\n",
            "Epoch 23/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.8109 - acc: 0.3660 - val_loss: 1.8105 - val_acc: 0.3669\n",
            "Epoch 24/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.8050 - acc: 0.3677 - val_loss: 1.8059 - val_acc: 0.3673\n",
            "Epoch 25/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.7994 - acc: 0.3689 - val_loss: 1.7996 - val_acc: 0.3694\n",
            "Epoch 26/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.7941 - acc: 0.3722 - val_loss: 1.7950 - val_acc: 0.3713\n",
            "Epoch 27/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.7889 - acc: 0.3724 - val_loss: 1.7898 - val_acc: 0.3751\n",
            "Epoch 28/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.7836 - acc: 0.3751 - val_loss: 1.7846 - val_acc: 0.3760\n",
            "Epoch 29/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7787 - acc: 0.3768 - val_loss: 1.7802 - val_acc: 0.3730\n",
            "Epoch 30/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.7738 - acc: 0.3797 - val_loss: 1.7747 - val_acc: 0.3786\n",
            "Epoch 31/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.7690 - acc: 0.3812 - val_loss: 1.7689 - val_acc: 0.3811\n",
            "Epoch 32/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7643 - acc: 0.3824 - val_loss: 1.7643 - val_acc: 0.3806\n",
            "Epoch 33/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7596 - acc: 0.3850 - val_loss: 1.7600 - val_acc: 0.3807\n",
            "Epoch 34/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7553 - acc: 0.3864 - val_loss: 1.7556 - val_acc: 0.3837\n",
            "Epoch 35/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7507 - acc: 0.3888 - val_loss: 1.7512 - val_acc: 0.3848\n",
            "Epoch 36/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7463 - acc: 0.3902 - val_loss: 1.7474 - val_acc: 0.3854\n",
            "Epoch 37/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7421 - acc: 0.3921 - val_loss: 1.7439 - val_acc: 0.3886\n",
            "Epoch 38/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.7377 - acc: 0.3938 - val_loss: 1.7385 - val_acc: 0.3894\n",
            "Epoch 39/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.7338 - acc: 0.3948 - val_loss: 1.7358 - val_acc: 0.3925\n",
            "Epoch 40/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7295 - acc: 0.3959 - val_loss: 1.7313 - val_acc: 0.3925\n",
            "Epoch 41/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7257 - acc: 0.3983 - val_loss: 1.7271 - val_acc: 0.3968\n",
            "Epoch 42/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.7218 - acc: 0.3991 - val_loss: 1.7231 - val_acc: 0.3939\n",
            "Epoch 43/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.7177 - acc: 0.4011 - val_loss: 1.7198 - val_acc: 0.3977\n",
            "Epoch 44/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.7139 - acc: 0.4040 - val_loss: 1.7151 - val_acc: 0.3971\n",
            "Epoch 45/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.7103 - acc: 0.4041 - val_loss: 1.7128 - val_acc: 0.4014\n",
            "Epoch 46/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7062 - acc: 0.4039 - val_loss: 1.7087 - val_acc: 0.4019\n",
            "Epoch 47/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.7028 - acc: 0.4071 - val_loss: 1.7049 - val_acc: 0.4050\n",
            "Epoch 48/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.6993 - acc: 0.4080 - val_loss: 1.7028 - val_acc: 0.4012\n",
            "Epoch 49/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.6956 - acc: 0.4103 - val_loss: 1.6984 - val_acc: 0.4055\n",
            "Epoch 50/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6919 - acc: 0.4112 - val_loss: 1.6959 - val_acc: 0.4103\n",
            "Epoch 51/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.6888 - acc: 0.4126 - val_loss: 1.6931 - val_acc: 0.4075\n",
            "Epoch 52/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.6852 - acc: 0.4134 - val_loss: 1.6885 - val_acc: 0.4105\n",
            "Epoch 53/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6817 - acc: 0.4144 - val_loss: 1.6859 - val_acc: 0.4108\n",
            "Epoch 54/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.6785 - acc: 0.4158 - val_loss: 1.6841 - val_acc: 0.4112\n",
            "Epoch 55/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.6749 - acc: 0.4180 - val_loss: 1.6791 - val_acc: 0.4160\n",
            "Epoch 56/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6719 - acc: 0.4179 - val_loss: 1.6772 - val_acc: 0.4128\n",
            "Epoch 57/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.6686 - acc: 0.4196 - val_loss: 1.6719 - val_acc: 0.4178\n",
            "Epoch 58/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6652 - acc: 0.4200 - val_loss: 1.6702 - val_acc: 0.4185\n",
            "Epoch 59/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6620 - acc: 0.4224 - val_loss: 1.6670 - val_acc: 0.4176\n",
            "Epoch 60/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6589 - acc: 0.4235 - val_loss: 1.6676 - val_acc: 0.4172\n",
            "Epoch 61/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.6559 - acc: 0.4247 - val_loss: 1.6598 - val_acc: 0.4207\n",
            "Epoch 62/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6528 - acc: 0.4247 - val_loss: 1.6572 - val_acc: 0.4237\n",
            "Epoch 63/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6496 - acc: 0.4268 - val_loss: 1.6550 - val_acc: 0.4222\n",
            "Epoch 64/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6468 - acc: 0.4269 - val_loss: 1.6518 - val_acc: 0.4237\n",
            "Epoch 65/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6438 - acc: 0.4280 - val_loss: 1.6496 - val_acc: 0.4219\n",
            "Epoch 66/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.6405 - acc: 0.4295 - val_loss: 1.6473 - val_acc: 0.4256\n",
            "Epoch 67/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.6378 - acc: 0.4311 - val_loss: 1.6464 - val_acc: 0.4273\n",
            "Epoch 68/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.6347 - acc: 0.4311 - val_loss: 1.6441 - val_acc: 0.4249\n",
            "Epoch 69/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.6320 - acc: 0.4328 - val_loss: 1.6384 - val_acc: 0.4287\n",
            "Epoch 70/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.6294 - acc: 0.4333 - val_loss: 1.6361 - val_acc: 0.4310\n",
            "Epoch 71/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6263 - acc: 0.4340 - val_loss: 1.6332 - val_acc: 0.4271\n",
            "Epoch 72/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.6237 - acc: 0.4345 - val_loss: 1.6317 - val_acc: 0.4313\n",
            "Epoch 73/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6207 - acc: 0.4362 - val_loss: 1.6304 - val_acc: 0.4333\n",
            "Epoch 74/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6184 - acc: 0.4372 - val_loss: 1.6257 - val_acc: 0.4336\n",
            "Epoch 75/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6156 - acc: 0.4380 - val_loss: 1.6237 - val_acc: 0.4342\n",
            "Epoch 76/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6129 - acc: 0.4377 - val_loss: 1.6221 - val_acc: 0.4326\n",
            "Epoch 77/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6102 - acc: 0.4397 - val_loss: 1.6227 - val_acc: 0.4355\n",
            "Epoch 78/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6078 - acc: 0.4402 - val_loss: 1.6179 - val_acc: 0.4321\n",
            "Epoch 79/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6052 - acc: 0.4417 - val_loss: 1.6189 - val_acc: 0.4320\n",
            "Epoch 80/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6024 - acc: 0.4421 - val_loss: 1.6141 - val_acc: 0.4334\n",
            "Epoch 81/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6001 - acc: 0.4429 - val_loss: 1.6129 - val_acc: 0.4368\n",
            "Epoch 82/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5974 - acc: 0.4437 - val_loss: 1.6094 - val_acc: 0.4365\n",
            "Epoch 83/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5950 - acc: 0.4453 - val_loss: 1.6068 - val_acc: 0.4353\n",
            "Epoch 84/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5924 - acc: 0.4453 - val_loss: 1.6025 - val_acc: 0.4379\n",
            "Epoch 85/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5900 - acc: 0.4460 - val_loss: 1.6034 - val_acc: 0.4387\n",
            "Epoch 86/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5876 - acc: 0.4478 - val_loss: 1.5987 - val_acc: 0.4396\n",
            "Epoch 87/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5851 - acc: 0.4476 - val_loss: 1.5971 - val_acc: 0.4396\n",
            "Epoch 88/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5829 - acc: 0.4478 - val_loss: 1.5980 - val_acc: 0.4374\n",
            "Epoch 89/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5806 - acc: 0.4494 - val_loss: 1.5941 - val_acc: 0.4452\n",
            "Epoch 90/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5778 - acc: 0.4494 - val_loss: 1.5966 - val_acc: 0.4427\n",
            "Epoch 91/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5761 - acc: 0.4507 - val_loss: 1.5899 - val_acc: 0.4449\n",
            "Epoch 92/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5737 - acc: 0.4523 - val_loss: 1.5890 - val_acc: 0.4455\n",
            "Epoch 93/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5713 - acc: 0.4521 - val_loss: 1.5865 - val_acc: 0.4436\n",
            "Epoch 94/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5688 - acc: 0.4531 - val_loss: 1.5860 - val_acc: 0.4404\n",
            "Epoch 95/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5665 - acc: 0.4524 - val_loss: 1.5816 - val_acc: 0.4444\n",
            "Epoch 96/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5647 - acc: 0.4547 - val_loss: 1.5787 - val_acc: 0.4471\n",
            "Epoch 97/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5624 - acc: 0.4550 - val_loss: 1.5789 - val_acc: 0.4492\n",
            "Epoch 98/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5603 - acc: 0.4548 - val_loss: 1.5843 - val_acc: 0.4428\n",
            "Epoch 99/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5581 - acc: 0.4572 - val_loss: 1.5741 - val_acc: 0.4475\n",
            "Epoch 100/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.5558 - acc: 0.4565 - val_loss: 1.5742 - val_acc: 0.4498\n",
            "Epoch 101/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5538 - acc: 0.4569 - val_loss: 1.5699 - val_acc: 0.4493\n",
            "Epoch 102/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.5517 - acc: 0.4576 - val_loss: 1.5725 - val_acc: 0.4491\n",
            "Epoch 103/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5495 - acc: 0.4591 - val_loss: 1.5680 - val_acc: 0.4500\n",
            "Epoch 104/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5476 - acc: 0.4601 - val_loss: 1.5671 - val_acc: 0.4477\n",
            "Epoch 105/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5453 - acc: 0.4593 - val_loss: 1.5632 - val_acc: 0.4518\n",
            "Epoch 106/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5434 - acc: 0.4610 - val_loss: 1.5633 - val_acc: 0.4514\n",
            "Epoch 107/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5412 - acc: 0.4625 - val_loss: 1.5599 - val_acc: 0.4528\n",
            "Epoch 108/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.5396 - acc: 0.4625 - val_loss: 1.5599 - val_acc: 0.4491\n",
            "Epoch 109/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.5371 - acc: 0.4628 - val_loss: 1.5584 - val_acc: 0.4527\n",
            "Epoch 110/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5351 - acc: 0.4637 - val_loss: 1.5550 - val_acc: 0.4559\n",
            "Epoch 111/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5333 - acc: 0.4649 - val_loss: 1.5549 - val_acc: 0.4534\n",
            "Epoch 112/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5313 - acc: 0.4649 - val_loss: 1.5534 - val_acc: 0.4537\n",
            "Epoch 113/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5292 - acc: 0.4663 - val_loss: 1.5552 - val_acc: 0.4556\n",
            "Epoch 114/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5276 - acc: 0.4664 - val_loss: 1.5514 - val_acc: 0.4570\n",
            "Epoch 115/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5254 - acc: 0.4671 - val_loss: 1.5479 - val_acc: 0.4548\n",
            "Epoch 116/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5235 - acc: 0.4685 - val_loss: 1.5463 - val_acc: 0.4587\n",
            "Epoch 117/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5215 - acc: 0.4689 - val_loss: 1.5445 - val_acc: 0.4565\n",
            "Epoch 118/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5196 - acc: 0.4704 - val_loss: 1.5490 - val_acc: 0.4550\n",
            "Epoch 119/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5178 - acc: 0.4701 - val_loss: 1.5439 - val_acc: 0.4556\n",
            "Epoch 120/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5161 - acc: 0.4705 - val_loss: 1.5457 - val_acc: 0.4543\n",
            "Epoch 121/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5140 - acc: 0.4716 - val_loss: 1.5392 - val_acc: 0.4587\n",
            "Epoch 122/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5121 - acc: 0.4715 - val_loss: 1.5451 - val_acc: 0.4557\n",
            "Epoch 123/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5108 - acc: 0.4723 - val_loss: 1.5368 - val_acc: 0.4578\n",
            "Epoch 124/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.5084 - acc: 0.4740 - val_loss: 1.5346 - val_acc: 0.4598\n",
            "Epoch 125/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.5066 - acc: 0.4748 - val_loss: 1.5372 - val_acc: 0.4629\n",
            "Epoch 126/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.5050 - acc: 0.4744 - val_loss: 1.5376 - val_acc: 0.4621\n",
            "Epoch 127/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.5032 - acc: 0.4751 - val_loss: 1.5307 - val_acc: 0.4632\n",
            "Epoch 128/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.5014 - acc: 0.4753 - val_loss: 1.5290 - val_acc: 0.4609\n",
            "Epoch 129/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4997 - acc: 0.4772 - val_loss: 1.5279 - val_acc: 0.4635\n",
            "Epoch 130/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4977 - acc: 0.4775 - val_loss: 1.5266 - val_acc: 0.4656\n",
            "Epoch 131/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4961 - acc: 0.4772 - val_loss: 1.5276 - val_acc: 0.4648\n",
            "Epoch 132/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4943 - acc: 0.4784 - val_loss: 1.5386 - val_acc: 0.4592\n",
            "Epoch 133/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4930 - acc: 0.4790 - val_loss: 1.5229 - val_acc: 0.4646\n",
            "Epoch 134/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4906 - acc: 0.4802 - val_loss: 1.5206 - val_acc: 0.4652\n",
            "Epoch 135/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4895 - acc: 0.4804 - val_loss: 1.5211 - val_acc: 0.4622\n",
            "Epoch 136/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4878 - acc: 0.4796 - val_loss: 1.5182 - val_acc: 0.4670\n",
            "Epoch 137/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4855 - acc: 0.4812 - val_loss: 1.5191 - val_acc: 0.4656\n",
            "Epoch 138/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4841 - acc: 0.4823 - val_loss: 1.5158 - val_acc: 0.4697\n",
            "Epoch 139/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4825 - acc: 0.4827 - val_loss: 1.5137 - val_acc: 0.4693\n",
            "Epoch 140/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4809 - acc: 0.4823 - val_loss: 1.5178 - val_acc: 0.4641\n",
            "Epoch 141/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4790 - acc: 0.4839 - val_loss: 1.5128 - val_acc: 0.4696\n",
            "Epoch 142/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4772 - acc: 0.4848 - val_loss: 1.5148 - val_acc: 0.4662\n",
            "Epoch 143/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4758 - acc: 0.4844 - val_loss: 1.5093 - val_acc: 0.4695\n",
            "Epoch 144/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4740 - acc: 0.4855 - val_loss: 1.5085 - val_acc: 0.4690\n",
            "Epoch 145/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4721 - acc: 0.4851 - val_loss: 1.5070 - val_acc: 0.4697\n",
            "Epoch 146/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4707 - acc: 0.4865 - val_loss: 1.5072 - val_acc: 0.4669\n",
            "Epoch 147/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4690 - acc: 0.4865 - val_loss: 1.5042 - val_acc: 0.4709\n",
            "Epoch 148/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4677 - acc: 0.4881 - val_loss: 1.5033 - val_acc: 0.4714\n",
            "Epoch 149/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4657 - acc: 0.4890 - val_loss: 1.5034 - val_acc: 0.4729\n",
            "Epoch 150/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4642 - acc: 0.4886 - val_loss: 1.5032 - val_acc: 0.4698\n",
            "Epoch 151/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.4628 - acc: 0.4884 - val_loss: 1.5000 - val_acc: 0.4739\n",
            "Epoch 152/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.4609 - acc: 0.4891 - val_loss: 1.4989 - val_acc: 0.4721\n",
            "Epoch 153/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.4594 - acc: 0.4896 - val_loss: 1.5045 - val_acc: 0.4691\n",
            "Epoch 154/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.4578 - acc: 0.4901 - val_loss: 1.4964 - val_acc: 0.4745\n",
            "Epoch 155/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.4563 - acc: 0.4902 - val_loss: 1.5001 - val_acc: 0.4733\n",
            "Epoch 156/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.4547 - acc: 0.4920 - val_loss: 1.4934 - val_acc: 0.4743\n",
            "Epoch 157/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.4528 - acc: 0.4931 - val_loss: 1.4955 - val_acc: 0.4737\n",
            "Epoch 158/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.4512 - acc: 0.4932 - val_loss: 1.4933 - val_acc: 0.4760\n",
            "Epoch 159/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.4498 - acc: 0.4932 - val_loss: 1.4934 - val_acc: 0.4747\n",
            "Epoch 160/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.4484 - acc: 0.4949 - val_loss: 1.4923 - val_acc: 0.4753\n",
            "Epoch 161/500\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.4471 - acc: 0.4946 - val_loss: 1.4894 - val_acc: 0.4757\n",
            "Epoch 162/500\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.4454 - acc: 0.4946 - val_loss: 1.4917 - val_acc: 0.4739\n",
            "Epoch 163/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.4438 - acc: 0.4948 - val_loss: 1.4919 - val_acc: 0.4776\n",
            "Epoch 164/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.4426 - acc: 0.4954 - val_loss: 1.4865 - val_acc: 0.4792\n",
            "Epoch 165/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.4406 - acc: 0.4975 - val_loss: 1.4854 - val_acc: 0.4760\n",
            "Epoch 166/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.4389 - acc: 0.4981 - val_loss: 1.4844 - val_acc: 0.4762\n",
            "Epoch 167/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.4375 - acc: 0.4971 - val_loss: 1.4882 - val_acc: 0.4748\n",
            "Epoch 168/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.4368 - acc: 0.4988 - val_loss: 1.4837 - val_acc: 0.4789\n",
            "Epoch 169/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.4345 - acc: 0.4991 - val_loss: 1.4852 - val_acc: 0.4774\n",
            "Epoch 170/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.4328 - acc: 0.4995 - val_loss: 1.4773 - val_acc: 0.4810\n",
            "Epoch 171/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.4316 - acc: 0.5010 - val_loss: 1.4818 - val_acc: 0.4778\n",
            "Epoch 172/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.4303 - acc: 0.5007 - val_loss: 1.4818 - val_acc: 0.4821\n",
            "Epoch 173/500\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.4284 - acc: 0.4996 - val_loss: 1.4817 - val_acc: 0.4774\n",
            "Epoch 174/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4271 - acc: 0.5004 - val_loss: 1.4761 - val_acc: 0.4809\n",
            "Epoch 175/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4257 - acc: 0.5018 - val_loss: 1.4771 - val_acc: 0.4802\n",
            "Epoch 176/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4240 - acc: 0.5034 - val_loss: 1.4749 - val_acc: 0.4810\n",
            "Epoch 177/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4229 - acc: 0.5033 - val_loss: 1.4729 - val_acc: 0.4797\n",
            "Epoch 178/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4211 - acc: 0.5037 - val_loss: 1.4738 - val_acc: 0.4813\n",
            "Epoch 179/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4199 - acc: 0.5042 - val_loss: 1.4720 - val_acc: 0.4839\n",
            "Epoch 180/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4183 - acc: 0.5053 - val_loss: 1.4688 - val_acc: 0.4838\n",
            "Epoch 181/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.4171 - acc: 0.5061 - val_loss: 1.4770 - val_acc: 0.4806\n",
            "Epoch 182/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4157 - acc: 0.5060 - val_loss: 1.4692 - val_acc: 0.4800\n",
            "Epoch 183/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4140 - acc: 0.5061 - val_loss: 1.4673 - val_acc: 0.4813\n",
            "Epoch 184/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.4127 - acc: 0.5074 - val_loss: 1.4674 - val_acc: 0.4867\n",
            "Epoch 185/500\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.4108 - acc: 0.5075 - val_loss: 1.4679 - val_acc: 0.4814\n",
            "Epoch 186/500\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.4091 - acc: 0.5073 - val_loss: 1.4709 - val_acc: 0.4810\n",
            "Epoch 187/500\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.4082 - acc: 0.5082 - val_loss: 1.4614 - val_acc: 0.4860\n",
            "Epoch 188/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.4069 - acc: 0.5106 - val_loss: 1.4624 - val_acc: 0.4856\n",
            "Epoch 189/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.4055 - acc: 0.5088 - val_loss: 1.4695 - val_acc: 0.4861\n",
            "Epoch 190/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.4038 - acc: 0.5114 - val_loss: 1.4598 - val_acc: 0.4881\n",
            "Epoch 191/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.4025 - acc: 0.5109 - val_loss: 1.4610 - val_acc: 0.4880\n",
            "Epoch 192/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.4010 - acc: 0.5108 - val_loss: 1.4629 - val_acc: 0.4851\n",
            "Epoch 193/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.3996 - acc: 0.5115 - val_loss: 1.4649 - val_acc: 0.4842\n",
            "Epoch 194/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.3984 - acc: 0.5131 - val_loss: 1.4565 - val_acc: 0.4891\n",
            "Epoch 195/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.3966 - acc: 0.5126 - val_loss: 1.4599 - val_acc: 0.4846\n",
            "Epoch 196/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.3954 - acc: 0.5119 - val_loss: 1.4580 - val_acc: 0.4864\n",
            "Epoch 197/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.3945 - acc: 0.5132 - val_loss: 1.4576 - val_acc: 0.4863\n",
            "Epoch 198/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.3925 - acc: 0.5146 - val_loss: 1.4552 - val_acc: 0.4851\n",
            "Epoch 199/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3910 - acc: 0.5143 - val_loss: 1.4519 - val_acc: 0.4908\n",
            "Epoch 200/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.3900 - acc: 0.5150 - val_loss: 1.4575 - val_acc: 0.4862\n",
            "Epoch 201/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.3887 - acc: 0.5144 - val_loss: 1.4584 - val_acc: 0.4868\n",
            "Epoch 202/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.3870 - acc: 0.5145 - val_loss: 1.4566 - val_acc: 0.4888\n",
            "Epoch 203/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.3855 - acc: 0.5156 - val_loss: 1.4521 - val_acc: 0.4890\n",
            "Epoch 204/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.3844 - acc: 0.5153 - val_loss: 1.4504 - val_acc: 0.4903\n",
            "Epoch 205/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3827 - acc: 0.5165 - val_loss: 1.4438 - val_acc: 0.4910\n",
            "Epoch 206/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.3817 - acc: 0.5174 - val_loss: 1.4435 - val_acc: 0.4937\n",
            "Epoch 207/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.3803 - acc: 0.5175 - val_loss: 1.4493 - val_acc: 0.4917\n",
            "Epoch 208/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.3792 - acc: 0.5186 - val_loss: 1.4446 - val_acc: 0.4906\n",
            "Epoch 209/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.3779 - acc: 0.5196 - val_loss: 1.4543 - val_acc: 0.4840\n",
            "Epoch 210/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.3763 - acc: 0.5191 - val_loss: 1.4411 - val_acc: 0.4938\n",
            "Epoch 211/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.3748 - acc: 0.5191 - val_loss: 1.4417 - val_acc: 0.4939\n",
            "Epoch 212/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.3740 - acc: 0.5196 - val_loss: 1.4643 - val_acc: 0.4839\n",
            "Epoch 213/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.3721 - acc: 0.5199 - val_loss: 1.4410 - val_acc: 0.4935\n",
            "Epoch 214/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.3705 - acc: 0.5221 - val_loss: 1.4481 - val_acc: 0.4932\n",
            "Epoch 215/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.3699 - acc: 0.5211 - val_loss: 1.4365 - val_acc: 0.4944\n",
            "Epoch 216/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3682 - acc: 0.5209 - val_loss: 1.4387 - val_acc: 0.4942\n",
            "Epoch 217/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3671 - acc: 0.5222 - val_loss: 1.4534 - val_acc: 0.4900\n",
            "Epoch 218/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3661 - acc: 0.5224 - val_loss: 1.4360 - val_acc: 0.4935\n",
            "Epoch 219/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3645 - acc: 0.5227 - val_loss: 1.4389 - val_acc: 0.4894\n",
            "Epoch 220/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3632 - acc: 0.5236 - val_loss: 1.4467 - val_acc: 0.4944\n",
            "Epoch 221/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3617 - acc: 0.5234 - val_loss: 1.4371 - val_acc: 0.4919\n",
            "Epoch 222/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3610 - acc: 0.5241 - val_loss: 1.4370 - val_acc: 0.4919\n",
            "Epoch 223/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3594 - acc: 0.5237 - val_loss: 1.4319 - val_acc: 0.4932\n",
            "Epoch 224/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3577 - acc: 0.5259 - val_loss: 1.4311 - val_acc: 0.4942\n",
            "Epoch 225/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.3565 - acc: 0.5269 - val_loss: 1.4349 - val_acc: 0.4963\n",
            "Epoch 226/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.3552 - acc: 0.5254 - val_loss: 1.4334 - val_acc: 0.4941\n",
            "Epoch 227/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.3539 - acc: 0.5265 - val_loss: 1.4504 - val_acc: 0.4875\n",
            "Epoch 228/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3528 - acc: 0.5276 - val_loss: 1.4270 - val_acc: 0.4968\n",
            "Epoch 229/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3515 - acc: 0.5278 - val_loss: 1.4364 - val_acc: 0.4906\n",
            "Epoch 230/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3502 - acc: 0.5278 - val_loss: 1.4339 - val_acc: 0.4897\n",
            "Epoch 231/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3483 - acc: 0.5285 - val_loss: 1.4269 - val_acc: 0.4982\n",
            "Epoch 232/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3468 - acc: 0.5293 - val_loss: 1.4266 - val_acc: 0.4948\n",
            "Epoch 233/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3462 - acc: 0.5284 - val_loss: 1.4298 - val_acc: 0.4966\n",
            "Epoch 234/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3452 - acc: 0.5280 - val_loss: 1.4288 - val_acc: 0.4973\n",
            "Epoch 235/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3438 - acc: 0.5302 - val_loss: 1.4235 - val_acc: 0.4970\n",
            "Epoch 236/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3421 - acc: 0.5310 - val_loss: 1.4431 - val_acc: 0.4900\n",
            "Epoch 237/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3411 - acc: 0.5315 - val_loss: 1.4208 - val_acc: 0.5019\n",
            "Epoch 238/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3399 - acc: 0.5313 - val_loss: 1.4230 - val_acc: 0.5010\n",
            "Epoch 239/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3382 - acc: 0.5319 - val_loss: 1.4196 - val_acc: 0.5025\n",
            "Epoch 240/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3369 - acc: 0.5324 - val_loss: 1.4308 - val_acc: 0.4946\n",
            "Epoch 241/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3358 - acc: 0.5326 - val_loss: 1.4180 - val_acc: 0.5002\n",
            "Epoch 242/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3344 - acc: 0.5321 - val_loss: 1.4211 - val_acc: 0.4974\n",
            "Epoch 243/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3329 - acc: 0.5345 - val_loss: 1.4302 - val_acc: 0.4915\n",
            "Epoch 244/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3322 - acc: 0.5345 - val_loss: 1.4153 - val_acc: 0.5052\n",
            "Epoch 245/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3316 - acc: 0.5341 - val_loss: 1.4162 - val_acc: 0.5019\n",
            "Epoch 246/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3298 - acc: 0.5351 - val_loss: 1.4120 - val_acc: 0.5057\n",
            "Epoch 247/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3284 - acc: 0.5344 - val_loss: 1.4153 - val_acc: 0.5029\n",
            "Epoch 248/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3274 - acc: 0.5362 - val_loss: 1.4161 - val_acc: 0.4991\n",
            "Epoch 249/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3267 - acc: 0.5368 - val_loss: 1.4127 - val_acc: 0.5041\n",
            "Epoch 250/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3249 - acc: 0.5366 - val_loss: 1.4240 - val_acc: 0.4975\n",
            "Epoch 251/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3233 - acc: 0.5366 - val_loss: 1.4220 - val_acc: 0.4961\n",
            "Epoch 252/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3224 - acc: 0.5380 - val_loss: 1.4259 - val_acc: 0.4978\n",
            "Epoch 253/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3214 - acc: 0.5395 - val_loss: 1.4079 - val_acc: 0.5021\n",
            "Epoch 254/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3201 - acc: 0.5390 - val_loss: 1.4117 - val_acc: 0.5046\n",
            "Epoch 255/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3183 - acc: 0.5385 - val_loss: 1.4093 - val_acc: 0.5037\n",
            "Epoch 256/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3170 - acc: 0.5408 - val_loss: 1.4065 - val_acc: 0.5040\n",
            "Epoch 257/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3162 - acc: 0.5396 - val_loss: 1.4134 - val_acc: 0.5002\n",
            "Epoch 258/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3148 - acc: 0.5401 - val_loss: 1.4123 - val_acc: 0.4993\n",
            "Epoch 259/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3142 - acc: 0.5412 - val_loss: 1.4057 - val_acc: 0.5079\n",
            "Epoch 260/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3127 - acc: 0.5405 - val_loss: 1.4088 - val_acc: 0.5016\n",
            "Epoch 261/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3114 - acc: 0.5418 - val_loss: 1.4248 - val_acc: 0.4982\n",
            "Epoch 262/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3104 - acc: 0.5418 - val_loss: 1.4329 - val_acc: 0.4948\n",
            "Epoch 263/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3089 - acc: 0.5428 - val_loss: 1.4127 - val_acc: 0.5018\n",
            "Epoch 264/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3075 - acc: 0.5426 - val_loss: 1.4185 - val_acc: 0.4986\n",
            "Epoch 265/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3059 - acc: 0.5434 - val_loss: 1.4085 - val_acc: 0.5013\n",
            "Epoch 266/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3054 - acc: 0.5447 - val_loss: 1.3998 - val_acc: 0.5058\n",
            "Epoch 267/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3043 - acc: 0.5439 - val_loss: 1.4116 - val_acc: 0.5030\n",
            "Epoch 268/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3032 - acc: 0.5441 - val_loss: 1.4129 - val_acc: 0.4945\n",
            "Epoch 269/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3019 - acc: 0.5454 - val_loss: 1.3998 - val_acc: 0.5068\n",
            "Epoch 270/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3005 - acc: 0.5461 - val_loss: 1.3977 - val_acc: 0.5063\n",
            "Epoch 271/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2995 - acc: 0.5466 - val_loss: 1.3980 - val_acc: 0.5106\n",
            "Epoch 272/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2981 - acc: 0.5460 - val_loss: 1.4008 - val_acc: 0.5045\n",
            "Epoch 273/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2966 - acc: 0.5474 - val_loss: 1.4081 - val_acc: 0.4991\n",
            "Epoch 274/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2956 - acc: 0.5472 - val_loss: 1.4094 - val_acc: 0.4976\n",
            "Epoch 275/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2946 - acc: 0.5476 - val_loss: 1.3969 - val_acc: 0.5051\n",
            "Epoch 276/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2938 - acc: 0.5480 - val_loss: 1.4130 - val_acc: 0.4991\n",
            "Epoch 277/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2922 - acc: 0.5485 - val_loss: 1.3985 - val_acc: 0.5051\n",
            "Epoch 278/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2911 - acc: 0.5485 - val_loss: 1.3979 - val_acc: 0.5041\n",
            "Epoch 279/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2900 - acc: 0.5502 - val_loss: 1.3964 - val_acc: 0.5025\n",
            "Epoch 280/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2887 - acc: 0.5506 - val_loss: 1.3902 - val_acc: 0.5104\n",
            "Epoch 281/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2873 - acc: 0.5496 - val_loss: 1.4108 - val_acc: 0.5039\n",
            "Epoch 282/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2862 - acc: 0.5499 - val_loss: 1.4047 - val_acc: 0.5014\n",
            "Epoch 283/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2851 - acc: 0.5513 - val_loss: 1.3987 - val_acc: 0.5086\n",
            "Epoch 284/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2837 - acc: 0.5514 - val_loss: 1.3986 - val_acc: 0.5071\n",
            "Epoch 285/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2833 - acc: 0.5514 - val_loss: 1.3919 - val_acc: 0.5066\n",
            "Epoch 286/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2814 - acc: 0.5528 - val_loss: 1.3912 - val_acc: 0.5051\n",
            "Epoch 287/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2804 - acc: 0.5527 - val_loss: 1.4012 - val_acc: 0.5030\n",
            "Epoch 288/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2789 - acc: 0.5533 - val_loss: 1.3963 - val_acc: 0.5039\n",
            "Epoch 289/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2781 - acc: 0.5535 - val_loss: 1.3885 - val_acc: 0.5092\n",
            "Epoch 290/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2766 - acc: 0.5546 - val_loss: 1.3906 - val_acc: 0.5070\n",
            "Epoch 291/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2758 - acc: 0.5540 - val_loss: 1.3934 - val_acc: 0.5079\n",
            "Epoch 292/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2747 - acc: 0.5557 - val_loss: 1.4045 - val_acc: 0.5009\n",
            "Epoch 293/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2734 - acc: 0.5555 - val_loss: 1.3923 - val_acc: 0.5093\n",
            "Epoch 294/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2721 - acc: 0.5558 - val_loss: 1.3827 - val_acc: 0.5118\n",
            "Epoch 295/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2708 - acc: 0.5568 - val_loss: 1.4056 - val_acc: 0.5012\n",
            "Epoch 296/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2702 - acc: 0.5578 - val_loss: 1.3846 - val_acc: 0.5107\n",
            "Epoch 297/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2692 - acc: 0.5570 - val_loss: 1.3982 - val_acc: 0.5033\n",
            "Epoch 298/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2677 - acc: 0.5572 - val_loss: 1.4027 - val_acc: 0.5041\n",
            "Epoch 299/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2666 - acc: 0.5583 - val_loss: 1.3807 - val_acc: 0.5117\n",
            "Epoch 300/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2661 - acc: 0.5584 - val_loss: 1.3821 - val_acc: 0.5094\n",
            "Epoch 301/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2639 - acc: 0.5585 - val_loss: 1.3846 - val_acc: 0.5093\n",
            "Epoch 302/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2633 - acc: 0.5600 - val_loss: 1.3860 - val_acc: 0.5110\n",
            "Epoch 303/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2628 - acc: 0.5583 - val_loss: 1.3863 - val_acc: 0.5058\n",
            "Epoch 304/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2611 - acc: 0.5606 - val_loss: 1.3884 - val_acc: 0.5072\n",
            "Epoch 305/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2605 - acc: 0.5595 - val_loss: 1.4049 - val_acc: 0.5049\n",
            "Epoch 306/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2589 - acc: 0.5612 - val_loss: 1.3753 - val_acc: 0.5126\n",
            "Epoch 307/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2571 - acc: 0.5628 - val_loss: 1.3963 - val_acc: 0.5034\n",
            "Epoch 308/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2570 - acc: 0.5613 - val_loss: 1.3797 - val_acc: 0.5129\n",
            "Epoch 309/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2552 - acc: 0.5622 - val_loss: 1.3896 - val_acc: 0.5066\n",
            "Epoch 310/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2544 - acc: 0.5607 - val_loss: 1.3897 - val_acc: 0.5046\n",
            "Epoch 311/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2530 - acc: 0.5638 - val_loss: 1.3885 - val_acc: 0.5019\n",
            "Epoch 312/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2530 - acc: 0.5627 - val_loss: 1.3815 - val_acc: 0.5092\n",
            "Epoch 313/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.2512 - acc: 0.5625 - val_loss: 1.3757 - val_acc: 0.5136\n",
            "Epoch 314/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.2499 - acc: 0.5644 - val_loss: 1.3775 - val_acc: 0.5108\n",
            "Epoch 315/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.2488 - acc: 0.5653 - val_loss: 1.3735 - val_acc: 0.5142\n",
            "Epoch 316/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.2475 - acc: 0.5643 - val_loss: 1.3731 - val_acc: 0.5136\n",
            "Epoch 317/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.2467 - acc: 0.5655 - val_loss: 1.3769 - val_acc: 0.5140\n",
            "Epoch 318/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.2455 - acc: 0.5655 - val_loss: 1.4069 - val_acc: 0.4976\n",
            "Epoch 319/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.2445 - acc: 0.5645 - val_loss: 1.3832 - val_acc: 0.5075\n",
            "Epoch 320/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.2430 - acc: 0.5660 - val_loss: 1.3746 - val_acc: 0.5123\n",
            "Epoch 321/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.2412 - acc: 0.5666 - val_loss: 1.3723 - val_acc: 0.5141\n",
            "Epoch 322/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.2401 - acc: 0.5667 - val_loss: 1.3787 - val_acc: 0.5114\n",
            "Epoch 323/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.2402 - acc: 0.5678 - val_loss: 1.3722 - val_acc: 0.5114\n",
            "Epoch 324/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.2389 - acc: 0.5692 - val_loss: 1.3756 - val_acc: 0.5124\n",
            "Epoch 325/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.2371 - acc: 0.5685 - val_loss: 1.3768 - val_acc: 0.5139\n",
            "Epoch 326/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.2361 - acc: 0.5690 - val_loss: 1.3959 - val_acc: 0.5056\n",
            "Epoch 327/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.2355 - acc: 0.5693 - val_loss: 1.3819 - val_acc: 0.5118\n",
            "Epoch 328/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.2347 - acc: 0.5687 - val_loss: 1.3718 - val_acc: 0.5138\n",
            "Epoch 329/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.2324 - acc: 0.5704 - val_loss: 1.3905 - val_acc: 0.5030\n",
            "Epoch 330/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.2318 - acc: 0.5703 - val_loss: 1.3712 - val_acc: 0.5124\n",
            "Epoch 331/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.2305 - acc: 0.5706 - val_loss: 1.3729 - val_acc: 0.5122\n",
            "Epoch 332/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.2300 - acc: 0.5709 - val_loss: 1.3655 - val_acc: 0.5135\n",
            "Epoch 333/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.2293 - acc: 0.5716 - val_loss: 1.3797 - val_acc: 0.5094\n",
            "Epoch 334/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.2275 - acc: 0.5713 - val_loss: 1.3717 - val_acc: 0.5177\n",
            "Epoch 335/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.2268 - acc: 0.5713 - val_loss: 1.3654 - val_acc: 0.5183\n",
            "Epoch 336/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.2250 - acc: 0.5727 - val_loss: 1.3830 - val_acc: 0.5098\n",
            "Epoch 337/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.2243 - acc: 0.5719 - val_loss: 1.3648 - val_acc: 0.5174\n",
            "Epoch 338/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.2224 - acc: 0.5746 - val_loss: 1.3915 - val_acc: 0.5092\n",
            "Epoch 339/500\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.2223 - acc: 0.5740 - val_loss: 1.3867 - val_acc: 0.5080\n",
            "Epoch 340/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.2209 - acc: 0.5733 - val_loss: 1.3834 - val_acc: 0.5070\n",
            "Epoch 341/500\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.2191 - acc: 0.5743 - val_loss: 1.3672 - val_acc: 0.5136\n",
            "Epoch 342/500\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.2198 - acc: 0.5738 - val_loss: 1.3797 - val_acc: 0.5118\n",
            "Epoch 343/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.2171 - acc: 0.5750 - val_loss: 1.3775 - val_acc: 0.5116\n",
            "Epoch 344/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.2163 - acc: 0.5758 - val_loss: 1.3678 - val_acc: 0.5151\n",
            "Epoch 345/500\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.2162 - acc: 0.5751 - val_loss: 1.3961 - val_acc: 0.5038\n",
            "Epoch 346/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.2150 - acc: 0.5770 - val_loss: 1.3741 - val_acc: 0.5130\n",
            "Epoch 347/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.2138 - acc: 0.5769 - val_loss: 1.3638 - val_acc: 0.5178\n",
            "Epoch 348/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.2122 - acc: 0.5767 - val_loss: 1.3848 - val_acc: 0.5086\n",
            "Epoch 349/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.2118 - acc: 0.5782 - val_loss: 1.3992 - val_acc: 0.4985\n",
            "Epoch 350/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.2105 - acc: 0.5772 - val_loss: 1.4187 - val_acc: 0.4969\n",
            "Epoch 351/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.2087 - acc: 0.5774 - val_loss: 1.3718 - val_acc: 0.5103\n",
            "Epoch 352/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.2089 - acc: 0.5786 - val_loss: 1.3745 - val_acc: 0.5139\n",
            "Epoch 353/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.2068 - acc: 0.5794 - val_loss: 1.3672 - val_acc: 0.5180\n",
            "Epoch 354/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2056 - acc: 0.5782 - val_loss: 1.3885 - val_acc: 0.5059\n",
            "Epoch 355/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.2058 - acc: 0.5802 - val_loss: 1.3596 - val_acc: 0.5187\n",
            "Epoch 356/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2043 - acc: 0.5798 - val_loss: 1.3564 - val_acc: 0.5186\n",
            "Epoch 357/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.2017 - acc: 0.5806 - val_loss: 1.3618 - val_acc: 0.5144\n",
            "Epoch 358/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.2019 - acc: 0.5805 - val_loss: 1.3781 - val_acc: 0.5071\n",
            "Epoch 359/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.2009 - acc: 0.5809 - val_loss: 1.3642 - val_acc: 0.5160\n",
            "Epoch 360/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1991 - acc: 0.5802 - val_loss: 1.3727 - val_acc: 0.5124\n",
            "Epoch 361/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1990 - acc: 0.5818 - val_loss: 1.3612 - val_acc: 0.5175\n",
            "Epoch 362/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1978 - acc: 0.5817 - val_loss: 1.3810 - val_acc: 0.5146\n",
            "Epoch 363/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.1968 - acc: 0.5828 - val_loss: 1.3878 - val_acc: 0.5056\n",
            "Epoch 364/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1957 - acc: 0.5827 - val_loss: 1.3617 - val_acc: 0.5178\n",
            "Epoch 365/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1948 - acc: 0.5830 - val_loss: 1.3960 - val_acc: 0.5057\n",
            "Epoch 366/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.1928 - acc: 0.5832 - val_loss: 1.4075 - val_acc: 0.5003\n",
            "Epoch 367/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1930 - acc: 0.5851 - val_loss: 1.3870 - val_acc: 0.5082\n",
            "Epoch 368/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.1906 - acc: 0.5836 - val_loss: 1.3972 - val_acc: 0.5096\n",
            "Epoch 369/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.1893 - acc: 0.5854 - val_loss: 1.3617 - val_acc: 0.5204\n",
            "Epoch 370/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1894 - acc: 0.5853 - val_loss: 1.3585 - val_acc: 0.5185\n",
            "Epoch 371/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1882 - acc: 0.5856 - val_loss: 1.3533 - val_acc: 0.5212\n",
            "Epoch 372/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.1864 - acc: 0.5857 - val_loss: 1.3718 - val_acc: 0.5147\n",
            "Epoch 373/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1857 - acc: 0.5863 - val_loss: 1.3678 - val_acc: 0.5179\n",
            "Epoch 374/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1837 - acc: 0.5858 - val_loss: 1.3944 - val_acc: 0.5052\n",
            "Epoch 375/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.1828 - acc: 0.5876 - val_loss: 1.3686 - val_acc: 0.5134\n",
            "Epoch 376/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1835 - acc: 0.5876 - val_loss: 1.3703 - val_acc: 0.5178\n",
            "Epoch 377/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1822 - acc: 0.5878 - val_loss: 1.3490 - val_acc: 0.5226\n",
            "Epoch 378/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1805 - acc: 0.5885 - val_loss: 1.3626 - val_acc: 0.5223\n",
            "Epoch 379/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1789 - acc: 0.5877 - val_loss: 1.3644 - val_acc: 0.5134\n",
            "Epoch 380/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1787 - acc: 0.5883 - val_loss: 1.3588 - val_acc: 0.5212\n",
            "Epoch 381/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1773 - acc: 0.5886 - val_loss: 1.3523 - val_acc: 0.5214\n",
            "Epoch 382/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1765 - acc: 0.5904 - val_loss: 1.4128 - val_acc: 0.5016\n",
            "Epoch 383/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1755 - acc: 0.5904 - val_loss: 1.3468 - val_acc: 0.5216\n",
            "Epoch 384/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1741 - acc: 0.5900 - val_loss: 1.3516 - val_acc: 0.5219\n",
            "Epoch 385/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1746 - acc: 0.5885 - val_loss: 1.3506 - val_acc: 0.5248\n",
            "Epoch 386/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1728 - acc: 0.5905 - val_loss: 1.3589 - val_acc: 0.5187\n",
            "Epoch 387/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1718 - acc: 0.5906 - val_loss: 1.3879 - val_acc: 0.5069\n",
            "Epoch 388/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1704 - acc: 0.5917 - val_loss: 1.3782 - val_acc: 0.5148\n",
            "Epoch 389/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1692 - acc: 0.5925 - val_loss: 1.3606 - val_acc: 0.5173\n",
            "Epoch 390/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1690 - acc: 0.5923 - val_loss: 1.3611 - val_acc: 0.5177\n",
            "Epoch 391/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1672 - acc: 0.5927 - val_loss: 1.3477 - val_acc: 0.5262\n",
            "Epoch 392/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1652 - acc: 0.5928 - val_loss: 1.3556 - val_acc: 0.5195\n",
            "Epoch 393/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1645 - acc: 0.5936 - val_loss: 1.3780 - val_acc: 0.5097\n",
            "Epoch 394/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1637 - acc: 0.5933 - val_loss: 1.3524 - val_acc: 0.5192\n",
            "Epoch 395/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1631 - acc: 0.5935 - val_loss: 1.3638 - val_acc: 0.5143\n",
            "Epoch 396/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1613 - acc: 0.5942 - val_loss: 1.3605 - val_acc: 0.5171\n",
            "Epoch 397/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1609 - acc: 0.5950 - val_loss: 1.4148 - val_acc: 0.4944\n",
            "Epoch 398/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1598 - acc: 0.5954 - val_loss: 1.3941 - val_acc: 0.5111\n",
            "Epoch 399/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1584 - acc: 0.5948 - val_loss: 1.3521 - val_acc: 0.5249\n",
            "Epoch 400/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1587 - acc: 0.5959 - val_loss: 1.3571 - val_acc: 0.5214\n",
            "Epoch 401/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1568 - acc: 0.5968 - val_loss: 1.3510 - val_acc: 0.5250\n",
            "Epoch 402/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1559 - acc: 0.5957 - val_loss: 1.3914 - val_acc: 0.5046\n",
            "Epoch 403/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1547 - acc: 0.5962 - val_loss: 1.3937 - val_acc: 0.5105\n",
            "Epoch 404/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1552 - acc: 0.5965 - val_loss: 1.3638 - val_acc: 0.5134\n",
            "Epoch 405/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1527 - acc: 0.5990 - val_loss: 1.3586 - val_acc: 0.5197\n",
            "Epoch 406/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1519 - acc: 0.5972 - val_loss: 1.3449 - val_acc: 0.5223\n",
            "Epoch 407/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1510 - acc: 0.5986 - val_loss: 1.3670 - val_acc: 0.5208\n",
            "Epoch 408/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1501 - acc: 0.5985 - val_loss: 1.3524 - val_acc: 0.5237\n",
            "Epoch 409/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1478 - acc: 0.5991 - val_loss: 1.3451 - val_acc: 0.5245\n",
            "Epoch 410/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1466 - acc: 0.5988 - val_loss: 1.3797 - val_acc: 0.5056\n",
            "Epoch 411/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1478 - acc: 0.6005 - val_loss: 1.3454 - val_acc: 0.5244\n",
            "Epoch 412/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1453 - acc: 0.5997 - val_loss: 1.3433 - val_acc: 0.5233\n",
            "Epoch 413/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1446 - acc: 0.5997 - val_loss: 1.3796 - val_acc: 0.5164\n",
            "Epoch 414/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1426 - acc: 0.6008 - val_loss: 1.3475 - val_acc: 0.5221\n",
            "Epoch 415/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1417 - acc: 0.6008 - val_loss: 1.3954 - val_acc: 0.5065\n",
            "Epoch 416/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1418 - acc: 0.6000 - val_loss: 1.3482 - val_acc: 0.5240\n",
            "Epoch 417/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1410 - acc: 0.6012 - val_loss: 1.3474 - val_acc: 0.5257\n",
            "Epoch 418/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1395 - acc: 0.6010 - val_loss: 1.3502 - val_acc: 0.5233\n",
            "Epoch 419/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1381 - acc: 0.6030 - val_loss: 1.3854 - val_acc: 0.5114\n",
            "Epoch 420/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1375 - acc: 0.6026 - val_loss: 1.3537 - val_acc: 0.5169\n",
            "Epoch 421/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1364 - acc: 0.6020 - val_loss: 1.3686 - val_acc: 0.5155\n",
            "Epoch 422/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1362 - acc: 0.6015 - val_loss: 1.4045 - val_acc: 0.5098\n",
            "Epoch 423/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1346 - acc: 0.6048 - val_loss: 1.3635 - val_acc: 0.5194\n",
            "Epoch 424/500\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 1.1321 - acc: 0.6048 - val_loss: 1.3433 - val_acc: 0.5266\n",
            "Epoch 425/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.1307 - acc: 0.6049 - val_loss: 1.3657 - val_acc: 0.5170\n",
            "Epoch 426/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1305 - acc: 0.6058 - val_loss: 1.3857 - val_acc: 0.5118\n",
            "Epoch 427/500\n",
            "50000/50000 [==============================] - 12s 234us/step - loss: 1.1311 - acc: 0.6043 - val_loss: 1.3368 - val_acc: 0.5264\n",
            "Epoch 428/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.1279 - acc: 0.6065 - val_loss: 1.3496 - val_acc: 0.5232\n",
            "Epoch 429/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1273 - acc: 0.6066 - val_loss: 1.3585 - val_acc: 0.5205\n",
            "Epoch 430/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1273 - acc: 0.6064 - val_loss: 1.3855 - val_acc: 0.5126\n",
            "Epoch 431/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1264 - acc: 0.6070 - val_loss: 1.3384 - val_acc: 0.5264\n",
            "Epoch 432/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1244 - acc: 0.6067 - val_loss: 1.3642 - val_acc: 0.5217\n",
            "Epoch 433/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1239 - acc: 0.6081 - val_loss: 1.3338 - val_acc: 0.5292\n",
            "Epoch 434/500\n",
            "50000/50000 [==============================] - 12s 233us/step - loss: 1.1222 - acc: 0.6075 - val_loss: 1.3676 - val_acc: 0.5213\n",
            "Epoch 435/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1226 - acc: 0.6085 - val_loss: 1.3509 - val_acc: 0.5296\n",
            "Epoch 436/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1211 - acc: 0.6100 - val_loss: 1.3742 - val_acc: 0.5166\n",
            "Epoch 437/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1210 - acc: 0.6093 - val_loss: 1.3530 - val_acc: 0.5213\n",
            "Epoch 438/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.1195 - acc: 0.6090 - val_loss: 1.3464 - val_acc: 0.5227\n",
            "Epoch 439/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1198 - acc: 0.6092 - val_loss: 1.3625 - val_acc: 0.5186\n",
            "Epoch 440/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1174 - acc: 0.6089 - val_loss: 1.3468 - val_acc: 0.5202\n",
            "Epoch 441/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.1151 - acc: 0.6115 - val_loss: 1.3362 - val_acc: 0.5290\n",
            "Epoch 442/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1152 - acc: 0.6102 - val_loss: 1.3384 - val_acc: 0.5240\n",
            "Epoch 443/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1148 - acc: 0.6087 - val_loss: 1.3388 - val_acc: 0.5282\n",
            "Epoch 444/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.1132 - acc: 0.6117 - val_loss: 1.3656 - val_acc: 0.5193\n",
            "Epoch 445/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1125 - acc: 0.6119 - val_loss: 1.3339 - val_acc: 0.5277\n",
            "Epoch 446/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1120 - acc: 0.6120 - val_loss: 1.3448 - val_acc: 0.5242\n",
            "Epoch 447/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.1102 - acc: 0.6126 - val_loss: 1.3788 - val_acc: 0.5082\n",
            "Epoch 448/500\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 1.1090 - acc: 0.6127 - val_loss: 1.3654 - val_acc: 0.5183\n",
            "Epoch 449/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1060 - acc: 0.6132 - val_loss: 1.3451 - val_acc: 0.5259\n",
            "Epoch 450/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.1074 - acc: 0.6132 - val_loss: 1.3395 - val_acc: 0.5279\n",
            "Epoch 451/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1055 - acc: 0.6131 - val_loss: 1.3505 - val_acc: 0.5211\n",
            "Epoch 452/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1045 - acc: 0.6163 - val_loss: 1.3553 - val_acc: 0.5191\n",
            "Epoch 453/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1045 - acc: 0.6141 - val_loss: 1.3631 - val_acc: 0.5202\n",
            "Epoch 454/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.1030 - acc: 0.6140 - val_loss: 1.3534 - val_acc: 0.5204\n",
            "Epoch 455/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1012 - acc: 0.6145 - val_loss: 1.3449 - val_acc: 0.5262\n",
            "Epoch 456/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0998 - acc: 0.6145 - val_loss: 1.3735 - val_acc: 0.5175\n",
            "Epoch 457/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1011 - acc: 0.6152 - val_loss: 1.3666 - val_acc: 0.5229\n",
            "Epoch 458/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0970 - acc: 0.6163 - val_loss: 1.3521 - val_acc: 0.5210\n",
            "Epoch 459/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0974 - acc: 0.6153 - val_loss: 1.3363 - val_acc: 0.5266\n",
            "Epoch 460/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0963 - acc: 0.6171 - val_loss: 1.3432 - val_acc: 0.5251\n",
            "Epoch 461/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0951 - acc: 0.6173 - val_loss: 1.3783 - val_acc: 0.5199\n",
            "Epoch 462/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0945 - acc: 0.6181 - val_loss: 1.3352 - val_acc: 0.5280\n",
            "Epoch 463/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0951 - acc: 0.6168 - val_loss: 1.3485 - val_acc: 0.5218\n",
            "Epoch 464/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0934 - acc: 0.6174 - val_loss: 1.4122 - val_acc: 0.5073\n",
            "Epoch 465/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0921 - acc: 0.6175 - val_loss: 1.3522 - val_acc: 0.5248\n",
            "Epoch 466/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0893 - acc: 0.6204 - val_loss: 1.3423 - val_acc: 0.5244\n",
            "Epoch 467/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0906 - acc: 0.6193 - val_loss: 1.3723 - val_acc: 0.5107\n",
            "Epoch 468/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0886 - acc: 0.6191 - val_loss: 1.3992 - val_acc: 0.5047\n",
            "Epoch 469/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0876 - acc: 0.6201 - val_loss: 1.3412 - val_acc: 0.5256\n",
            "Epoch 470/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0862 - acc: 0.6212 - val_loss: 1.3447 - val_acc: 0.5274\n",
            "Epoch 471/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0867 - acc: 0.6202 - val_loss: 1.3324 - val_acc: 0.5300\n",
            "Epoch 472/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0847 - acc: 0.6214 - val_loss: 1.3748 - val_acc: 0.5158\n",
            "Epoch 473/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0830 - acc: 0.6219 - val_loss: 1.3609 - val_acc: 0.5202\n",
            "Epoch 474/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0816 - acc: 0.6230 - val_loss: 1.3504 - val_acc: 0.5291\n",
            "Epoch 475/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0830 - acc: 0.6206 - val_loss: 1.3705 - val_acc: 0.5195\n",
            "Epoch 476/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0814 - acc: 0.6217 - val_loss: 1.3778 - val_acc: 0.5143\n",
            "Epoch 477/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0818 - acc: 0.6221 - val_loss: 1.3401 - val_acc: 0.5272\n",
            "Epoch 478/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0812 - acc: 0.6227 - val_loss: 1.3828 - val_acc: 0.5069\n",
            "Epoch 479/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0766 - acc: 0.6239 - val_loss: 1.3400 - val_acc: 0.5275\n",
            "Epoch 480/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0780 - acc: 0.6236 - val_loss: 1.3401 - val_acc: 0.5266\n",
            "Epoch 481/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0775 - acc: 0.6241 - val_loss: 1.3463 - val_acc: 0.5301\n",
            "Epoch 482/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0756 - acc: 0.6252 - val_loss: 1.3314 - val_acc: 0.5297\n",
            "Epoch 483/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0738 - acc: 0.6251 - val_loss: 1.4322 - val_acc: 0.5040\n",
            "Epoch 484/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0753 - acc: 0.6243 - val_loss: 1.3615 - val_acc: 0.5252\n",
            "Epoch 485/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0725 - acc: 0.6251 - val_loss: 1.3663 - val_acc: 0.5217\n",
            "Epoch 486/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0709 - acc: 0.6273 - val_loss: 1.3442 - val_acc: 0.5269\n",
            "Epoch 487/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0688 - acc: 0.6273 - val_loss: 1.3360 - val_acc: 0.5287\n",
            "Epoch 488/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0682 - acc: 0.6280 - val_loss: 1.3518 - val_acc: 0.5218\n",
            "Epoch 489/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0676 - acc: 0.6274 - val_loss: 1.3502 - val_acc: 0.5246\n",
            "Epoch 490/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0680 - acc: 0.6286 - val_loss: 1.3441 - val_acc: 0.5234\n",
            "Epoch 491/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0654 - acc: 0.6276 - val_loss: 1.3833 - val_acc: 0.5149\n",
            "Epoch 492/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0671 - acc: 0.6258 - val_loss: 1.3451 - val_acc: 0.5257\n",
            "Epoch 493/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0625 - acc: 0.6295 - val_loss: 1.3742 - val_acc: 0.5209\n",
            "Epoch 494/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.0647 - acc: 0.6293 - val_loss: 1.3502 - val_acc: 0.5292\n",
            "Epoch 495/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.0665 - acc: 0.6270 - val_loss: 1.3502 - val_acc: 0.5215\n",
            "Epoch 496/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0619 - acc: 0.6294 - val_loss: 1.3762 - val_acc: 0.5191\n",
            "Epoch 497/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0616 - acc: 0.6299 - val_loss: 1.3493 - val_acc: 0.5227\n",
            "Epoch 498/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0580 - acc: 0.6309 - val_loss: 1.3441 - val_acc: 0.5264\n",
            "Epoch 499/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0597 - acc: 0.6298 - val_loss: 1.3686 - val_acc: 0.5155\n",
            "Epoch 500/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.0583 - acc: 0.6320 - val_loss: 1.3448 - val_acc: 0.5259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac0b131198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwHvMLOo2bpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "5c9f0c0e-7084-4d3f-f2a1-0013ef5d83e2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 以視覺畫方式檢視訓練過程\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAfScFdKKQ+k4a6UUh5Iw10ppTzQ/wM7/v6kYnNfggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}