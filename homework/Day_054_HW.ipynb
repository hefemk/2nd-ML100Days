{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 作業1\n",
    "請觀看 Coursera Andrew Ng 教授的影片。影片裡會講授 unsupervised learning 概念，及會介紹很多其應用場景。\n",
    "\n",
    "非監督學習\n",
    "> 在非監督式學習裡，會將一組未明確指示處理方式的資料集交給深度學習模型。訓練資料集是一組無特定期望結果或正確答案的例子，神經網路會嘗試擷取出有用特徵並分析其結構，以求自動找出資料結構。\n",
    "\n",
    "from https://blogs.nvidia.com.tw/2018/09/supervised-unsupervised-learning/\n",
    "\n",
    "* 資料是沒有 label 的，我們可以從中找出什麼結構？\n",
    "* 應用例子：分類系統、Organize computing clusters、Social network analysis、Market segmentation、Astronmical data analysis、分離音訊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業2\n",
    "試著想想看, 非監督學習是否有可能使用評價函數 (Metric) 來鑑別好壞呢?  \n",
    "(Hint : 可以分為 \"有目標值\" 與 \"無目標值\" 兩個方向思考)\n",
    "\n",
    "提示中的「目標值」是否對應 Label？就教材、影片了解到，非監督學習應該適用在無 Label 的情境下，意即自己也不知道正確答案，而讓演算法得出資料的結構、關係。\n",
    "\n",
    "如何評價非監督學習，以分類演算法為例，可以使用：\n",
    "\n",
    "> 分群演算法的績效衡量簡單明暸：組間差異大，組內差異小。而所謂的差異指的就是觀測值之間的距離遠近作為衡量，最常見還是使用歐氏距離（Euclidean distance）\n",
    "\n",
    "from https://ithelp.ithome.com.tw/articles/10187314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
